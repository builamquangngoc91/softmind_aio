{
 "metadata": {
  "kernelspec": {
   "language": "python",
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.11",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kaggle": {
   "accelerator": "none",
   "dataSources": [],
   "dockerImageVersionId": 31041,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook",
   "isGpuEnabled": false
  },
  "colab": {
   "provenance": []
  }
 },
 "nbformat_minor": 0,
 "nbformat": 4,
 "cells": [
  {
   "cell_type": "code",
   "source": [
    "%%capture\n",
    "import os\n",
    "if \"COLAB_\" not in \"\".join(os.environ.keys()):\n",
    "    !pip install unsloth\n",
    "else:\n",
    "    # Do this only in Colab notebooks! Otherwise use pip install unsloth\n",
    "    !pip install --no-deps bitsandbytes accelerate xformers==0.0.29.post3 peft trl triton cut_cross_entropy unsloth_zoo\n",
    "    !pip install sentencepiece protobuf \"datasets>=3.4.1\" huggingface_hub hf_transfer\n",
    "    !pip install --no-deps unsloth"
   ],
   "metadata": {
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "trusted": true,
    "id": "MpQD5CS2k1hw"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": "from huggingface_hub import login\nimport os\n\nlogin(token=os.getenv('HF_TOKEN', 'your_huggingface_token_here'))",
   "metadata": {
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2025-07-06T02:23:41.635890Z",
     "iopub.execute_input": "2025-07-06T02:23:41.636489Z",
     "iopub.status.idle": "2025-07-06T02:23:41.830449Z",
     "shell.execute_reply.started": "2025-07-06T02:23:41.636460Z",
     "shell.execute_reply": "2025-07-06T02:23:41.829852Z"
    },
    "id": "EDnAQR_xk1hx"
   },
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "from unsloth import FastLanguageModel\n",
    "import torch\n",
    "\n",
    "model, tokenizer = FastLanguageModel.from_pretrained(\n",
    "    model_name = \"thailevann/Qwen3-1.7B_CT_VLSP_track5\",\n",
    "    max_seq_length = 8192,\n",
    "    load_in_4bit = True,\n",
    "    load_in_8bit = False,\n",
    "    full_finetuning = False,\n",
    ")"
   ],
   "metadata": {
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2025-07-06T02:23:44.115904Z",
     "iopub.execute_input": "2025-07-06T02:23:44.116418Z",
     "iopub.status.idle": "2025-07-06T02:24:10.943970Z",
     "shell.execute_reply.started": "2025-07-06T02:23:44.116394Z",
     "shell.execute_reply": "2025-07-06T02:24:10.943137Z"
    },
    "id": "25UiPD4Mk1hy",
    "outputId": "641c9863-8f67-426e-c197-1e796f339339"
   },
   "outputs": [
    {
     "name": "stdout",
     "text": "ü¶• Unsloth: Will patch your computer to enable 2x faster free finetuning.\n",
     "output_type": "stream"
    },
    {
     "name": "stderr",
     "text": "2025-07-06 02:23:50.454187: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1751768630.479926     223 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1751768630.487646     223 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
     "output_type": "stream"
    },
    {
     "name": "stdout",
     "text": "ü¶• Unsloth Zoo will now patch everything to make training faster!\n",
     "output_type": "stream"
    },
    {
     "name": "stderr",
     "text": "/usr/local/lib/python3.11/dist-packages/peft/config.py:162: UserWarning: Unexpected keyword arguments ['alpha_pattern', 'bias', 'corda_config', 'eva_config', 'exclude_modules', 'fan_in_fan_out', 'init_lora_weights', 'layer_replication', 'layers_pattern', 'layers_to_transform', 'loftq_config', 'lora_alpha', 'lora_bias', 'lora_dropout', 'megatron_config', 'megatron_core', 'modules_to_save', 'qalora_group_size', 'r', 'rank_pattern', 'target_modules', 'trainable_token_indices', 'use_dora', 'use_qalora', 'use_rslora'] for class PeftConfig, these are ignored. This probably means that you're loading a configuration file that was saved using a higher version of the library and additional parameters have been introduced since. It is highly recommended to upgrade the PEFT version before continuing (e.g. by running `pip install -U peft`).\n  warnings.warn(\n",
     "output_type": "stream"
    },
    {
     "name": "stdout",
     "text": "==((====))==  Unsloth 2025.6.12: Fast Qwen3 patching. Transformers: 4.51.3.\n   \\\\   /|    Tesla P100-PCIE-16GB. Num GPUs = 1. Max memory: 15.888 GB. Platform: Linux.\nO^O/ \\_/ \\    Torch: 2.6.0+cu124. CUDA: 6.0. CUDA Toolkit: 12.4. Triton: 3.2.0\n\\        /    Bfloat16 = FALSE. FA [Xformers = 0.0.29.post3. FA2 = False]\n \"-____-\"     Free license: http://github.com/unslothai/unsloth\nUnsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n",
     "output_type": "stream"
    },
    {
     "name": "stderr",
     "text": "/usr/local/lib/python3.11/dist-packages/peft/config.py:162: UserWarning: Unexpected keyword arguments ['corda_config', 'qalora_group_size', 'trainable_token_indices', 'use_qalora'] for class LoraConfig, these are ignored. This probably means that you're loading a configuration file that was saved using a higher version of the library and additional parameters have been introduced since. It is highly recommended to upgrade the PEFT version before continuing (e.g. by running `pip install -U peft`).\n  warnings.warn(\nUnsloth 2025.6.12 patched 28 layers with 28 QKV layers, 28 O layers and 28 MLP layers.\n",
     "output_type": "stream"
    }
   ],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "!gdown 1OnxJ_UeJ_YXRX0E1U7lBIxqI9phaI6wq"
   ],
   "metadata": {
    "trusted": true,
    "id": "PCwzoGCAk1hz"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "!gdown 1GatkZT0nepRMC0G2lUxofP_9yKThwVlC"
   ],
   "metadata": {
    "trusted": true,
    "id": "bc5Sed3Mk1hz"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "from datasets import Dataset\n",
    "import json\n",
    "\n",
    "# B∆∞·ªõc 1: Load legal_corpus.json v√† t·∫°o map aid -> (law_id, content)\n",
    "aid2info = {}\n",
    "\n",
    "with open('legal_corpus.json', 'r', encoding='utf-8') as f:\n",
    "    corpus = json.load(f)\n",
    "\n",
    "for doc in corpus:\n",
    "    law_id = doc['law_id']\n",
    "    for article in doc['content']:\n",
    "        aid = article['aid']\n",
    "        content = article['content_Article']\n",
    "        aid2info[aid] = (law_id, content)\n",
    "\n",
    "# B∆∞·ªõc 2: Load train.json v√† format l·∫°i d·ªØ li·ªáu\n",
    "instruction_output_list = []\n",
    "\n",
    "with open('train.json', 'r', encoding='utf-8') as f:\n",
    "    train_data = json.load(f)\n",
    "\n",
    "for item in train_data:\n",
    "    question = item['question']\n",
    "    relevant_laws = item['relevant_laws']\n",
    "\n",
    "    output_parts = []\n",
    "    for idx, aid in enumerate(relevant_laws, start=1):\n",
    "        law_info = aid2info.get(aid)\n",
    "        if law_info:\n",
    "            law_id, content = law_info\n",
    "            output_parts.append(f\"Lu·∫≠t li√™n quan {idx}: {law_id}\\n{content}\")\n",
    "        else:\n",
    "            output_parts.append(f\"Lu·∫≠t li√™n quan {idx}: [Kh√¥ng t√¨m th·∫•y aid {aid}]\")\n",
    "\n",
    "    instruction_output_list.append({\n",
    "        \"instruction\": question,\n",
    "        \"output\": \"\\n\\n\".join(output_parts)\n",
    "    })\n",
    "\n",
    "# B∆∞·ªõc 3: T·∫°o dataset\n",
    "dataset = Dataset.from_list(instruction_output_list)\n"
   ],
   "metadata": {
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2025-07-06T02:24:14.100927Z",
     "iopub.execute_input": "2025-07-06T02:24:14.101618Z",
     "iopub.status.idle": "2025-07-06T02:24:15.817044Z",
     "shell.execute_reply.started": "2025-07-06T02:24:14.101591Z",
     "shell.execute_reply": "2025-07-06T02:24:15.816351Z"
    },
    "id": "xJeUzskFk1hz"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "dataset"
   ],
   "metadata": {
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2025-07-06T02:24:21.196513Z",
     "iopub.execute_input": "2025-07-06T02:24:21.197395Z",
     "iopub.status.idle": "2025-07-06T02:24:21.202940Z",
     "shell.execute_reply.started": "2025-07-06T02:24:21.197356Z",
     "shell.execute_reply": "2025-07-06T02:24:21.202118Z"
    },
    "id": "Kkb8B9U_k1hz",
    "outputId": "09478054-7cf0-4c87-f6be-e79ad1c3eb3e"
   },
   "outputs": [
    {
     "execution_count": 5,
     "output_type": "execute_result",
     "data": {
      "text/plain": "Dataset({\n    features: ['instruction', 'output'],\n    num_rows: 2190\n})"
     },
     "metadata": {}
    }
   ],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "# L·ªçc nh·ªØng m·∫´u KH√îNG c√≥ l√Ω do (reason_classification r·ªóng ho·∫∑c None)\n",
    "dataset_without_reasoning = dataset"
   ],
   "metadata": {
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2025-07-06T02:24:37.786679Z",
     "iopub.execute_input": "2025-07-06T02:24:37.787513Z",
     "iopub.status.idle": "2025-07-06T02:24:37.790988Z",
     "shell.execute_reply.started": "2025-07-06T02:24:37.787485Z",
     "shell.execute_reply": "2025-07-06T02:24:37.790348Z"
    },
    "id": "NqE_VyuQk1h0"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "def convert_conversations_to_chat_format_non_reasoning(examples):\n",
    "    question = examples.get(\"instruction\", \"\").strip()\n",
    "    answer = examples.get(\"output\", \"\").strip()\n",
    "\n",
    "    # B·ªè n·∫øu thi·∫øu n·ªôi dung\n",
    "    if not question or not answer:\n",
    "        return {\"conversation\": []}\n",
    "\n",
    "    # Prompt r√µ r√†ng, t·ª± nhi√™n\n",
    "    user_prompt = f\"\"\"B·∫°n l√† m·ªôt tr·ª£ l√Ω AI trong lƒ©nh v·ª±c ph√°p lu·∫≠t. Vui l√≤ng tr√≠ch d·∫´n c√°c ƒëi·ªÅu lu·∫≠t li√™n quan ƒë·∫øn c√¢u h·ªèi.\n",
    "\n",
    "    ## C√¢u h·ªèi:\n",
    "    {question}\n",
    "    \"\"\"\n",
    "\n",
    "    chat_conversations = [\n",
    "        {\"role\": \"user\", \"content\": user_prompt},\n",
    "        {\"role\": \"assistant\", \"content\": answer}\n",
    "    ]\n",
    "\n",
    "    return {\"conversation\": chat_conversations}\n"
   ],
   "metadata": {
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2025-07-06T02:24:49.707659Z",
     "iopub.execute_input": "2025-07-06T02:24:49.708291Z",
     "iopub.status.idle": "2025-07-06T02:24:49.713368Z",
     "shell.execute_reply.started": "2025-07-06T02:24:49.708266Z",
     "shell.execute_reply": "2025-07-06T02:24:49.712553Z"
    },
    "id": "wbsVxvtKk1h0"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "from unsloth.chat_templates import standardize_sharegpt\n",
    "from datasets import load_dataset, Dataset\n",
    "\n",
    "converted_data_non_reasoning = [convert_conversations_to_chat_format_non_reasoning(data) for data in dataset_without_reasoning]\n",
    "dataset_without_reasoning = Dataset.from_list(converted_data_non_reasoning )\n",
    "dataset_without_reasoning = standardize_sharegpt(dataset_without_reasoning)\n"
   ],
   "metadata": {
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2025-07-06T02:25:19.123397Z",
     "iopub.execute_input": "2025-07-06T02:25:19.123967Z",
     "iopub.status.idle": "2025-07-06T02:25:19.368331Z",
     "shell.execute_reply.started": "2025-07-06T02:25:19.123945Z",
     "shell.execute_reply": "2025-07-06T02:25:19.367731Z"
    },
    "id": "0iv0oMvMk1h0"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "non_reasoning_conversations = tokenizer.apply_chat_template(\n",
    "    dataset_without_reasoning[\"conversation\"],\n",
    "    tokenize = False,\n",
    ")\n"
   ],
   "metadata": {
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2025-07-06T02:25:22.996570Z",
     "iopub.execute_input": "2025-07-06T02:25:22.997224Z",
     "iopub.status.idle": "2025-07-06T02:25:23.279398Z",
     "shell.execute_reply.started": "2025-07-06T02:25:22.997203Z",
     "shell.execute_reply": "2025-07-06T02:25:23.278681Z"
    },
    "id": "NGIXdwVhk1h1"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "print(len(non_reasoning_conversations))"
   ],
   "metadata": {
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2025-07-06T02:25:33.976471Z",
     "iopub.execute_input": "2025-07-06T02:25:33.977213Z",
     "iopub.status.idle": "2025-07-06T02:25:33.980963Z",
     "shell.execute_reply.started": "2025-07-06T02:25:33.977189Z",
     "shell.execute_reply": "2025-07-06T02:25:33.980341Z"
    },
    "id": "nToVqy6Dk1h1",
    "outputId": "74118dcd-8e82-4766-c346-dccc972e9d74"
   },
   "outputs": [
    {
     "name": "stdout",
     "text": "2190\n",
     "output_type": "stream"
    }
   ],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "non_reasoning_subset = pd.Series(non_reasoning_conversations)"
   ],
   "metadata": {
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2025-07-06T02:25:40.756448Z",
     "iopub.execute_input": "2025-07-06T02:25:40.756743Z",
     "iopub.status.idle": "2025-07-06T02:25:40.762823Z",
     "shell.execute_reply.started": "2025-07-06T02:25:40.756722Z",
     "shell.execute_reply": "2025-07-06T02:25:40.762227Z"
    },
    "id": "cK9vinKpk1h1"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "'''\n",
    "data = pd.concat([\n",
    "    pd.Series(reasoning_conversations),\n",
    "    pd.Series(non_reasoning_subset)\n",
    "])\n",
    "'''\n",
    "#data = pd.Series(reasoning_conversations)\n",
    "data = pd.Series(non_reasoning_subset)\n",
    "\n",
    "data.name = \"text\"\n",
    "\n",
    "from datasets import Dataset\n",
    "combined_dataset = Dataset.from_pandas(pd.DataFrame(data))\n",
    "combined_dataset = combined_dataset.shuffle(seed = 3407)\n",
    "#combined_dataset = combined_dataset.remove_columns(\"__index_level_0__\")\n"
   ],
   "metadata": {
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2025-07-06T02:25:46.676306Z",
     "iopub.execute_input": "2025-07-06T02:25:46.676592Z",
     "iopub.status.idle": "2025-07-06T02:25:46.752289Z",
     "shell.execute_reply.started": "2025-07-06T02:25:46.676573Z",
     "shell.execute_reply": "2025-07-06T02:25:46.751736Z"
    },
    "id": "z21mdlffk1h1"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "from trl import SFTConfig, SFTTrainer\n",
    "\n",
    "\n",
    "trainer = SFTTrainer(\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    train_dataset=combined_dataset,\n",
    "    eval_dataset=None,\n",
    "    args=SFTConfig(\n",
    "        dataset_text_field=\"text\",\n",
    "        per_device_train_batch_size=1,\n",
    "        gradient_accumulation_steps=8,\n",
    "        num_train_epochs=3,\n",
    "        warmup_steps=50,\n",
    "        learning_rate=2e-5,\n",
    "        logging_steps=10,\n",
    "        optim=\"adamw_8bit\",\n",
    "        weight_decay=0.01,\n",
    "        lr_scheduler_type=\"cosine\",\n",
    "        seed=3407,\n",
    "        output_dir=\"./checkpoints\",\n",
    "        save_total_limit=2,\n",
    "        fp16=True,\n",
    "    ),\n",
    "\n",
    ")\n",
    "\n"
   ],
   "metadata": {
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2025-07-06T02:28:09.725421Z",
     "iopub.execute_input": "2025-07-06T02:28:09.725773Z",
     "iopub.status.idle": "2025-07-06T02:28:16.919162Z",
     "shell.execute_reply.started": "2025-07-06T02:28:09.725751Z",
     "shell.execute_reply": "2025-07-06T02:28:16.918340Z"
    },
    "colab": {
     "referenced_widgets": [
      "316328b316ca4364915e736197e0eac2"
     ]
    },
    "id": "ANEU0zBxk1h1",
    "outputId": "459260f0-23d9-434b-f160-9036a83f5fa0"
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "Unsloth: Tokenizing [\"text\"] (num_proc=4):   0%|          | 0/2190 [00:00<?, ? examples/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "316328b316ca4364915e736197e0eac2"
      }
     },
     "metadata": {}
    }
   ],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "trainer_stats = trainer.train()\n",
    "\n",
    "model.push_to_hub(\"thailevann/Qwen3-1.7B_SFT_VLSP_track5\")\n",
    "tokenizer.push_to_hub(\"thailevann/Qwen3-1.7B_SFT_VLSP_track5\")"
   ],
   "metadata": {
    "trusted": true,
    "id": "JsCmy2F8k1h1"
   },
   "outputs": [],
   "execution_count": null
  }
 ]
}