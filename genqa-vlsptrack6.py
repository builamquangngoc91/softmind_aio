from transformers import AutoModelForCausalLM, AutoTokenizer
import argparse
import logging
import sys

model_name = "Qwen/Qwen3-4B"

# load the tokenizer and the model
tokenizer = AutoTokenizer.from_pretrained(model_name)
model = AutoModelForCausalLM.from_pretrained(
    model_name,
    torch_dtype="auto",
    device_map="auto"
)

import os

from huggingface_hub import login
login(os.getenv("HF_TOKEN"))

from datasets import load_dataset
dataset = load_dataset("thailevann/vlsp_legal_pretrain")

def gen_data(relevant_doc, task):
    prompt = f"""
    Báº¡n lÃ  má»™t trá»£ lÃ½ phÃ¡p lÃ½. Dá»±a vÃ o tÃ i liá»‡u sau, hÃ£y táº¡o má»™t cÃ¢u há»i phÃ¡p lÃ½ thuá»™c dáº¡ng: {task},  
    vÃ  cung cáº¥p hai bá»™ cÃ¢u tráº£ lá»i:
    
    1. Má»™t **cÃ¢u tráº£ lá»i Ä‘Ãºng**, kÃ¨m theo **lÃ½ do há»£p lÃ½ (chosen_reason)**: viá»‡n dáº«n chÃ­nh xÃ¡c Ä‘iá»u luáº­t, phÃ¢n tÃ­ch Ä‘Ãºng trá»ng tÃ¢m ná»™i dung.
    
    2. Má»™t **cÃ¢u tráº£ lá»i sai**, kÃ¨m theo **má»™t chuá»—i suy nghÄ© sai (rejected_reason)**: Ä‘Ã¢y lÃ  má»™t quÃ¡ trÃ¬nh suy luáº­n **cÃ³ váº» há»£p lÃ½ nhÆ°ng dáº«n Ä‘áº¿n sai lá»‡ch**.  
    `rejected_reason` pháº£i thá»ƒ hiá»‡n cÃ¡ch má»™t ngÆ°á»i Ä‘á»c hiá»ƒu nháº§m luáº­t, **suy diá»…n sai**, hoáº·c **suy nghÄ© chÆ°a Ä‘áº§y Ä‘á»§**, tá»« Ä‘Ã³ dáº«n Ä‘áº¿n cÃ¢u tráº£ lá»i sai.
    
    âš ï¸ LÆ°u Ã½ quan trá»ng:
    - `rejected_reason` KHÃ”NG pháº£i lÃ  lá»i phÃª bÃ¬nh hay Ä‘Ã¡nh giÃ¡ cÃ¢u sai.
    - KHÃ”NG Ä‘Æ°á»£c nÃ³i kiá»ƒu: â€œCÃ¢u nÃ y sai vÃ¬...â€, â€œÄiá»u Ä‘Ã³ khÃ´ng Ä‘Ãºng...â€, â€œLuáº­t nÃ³i rÃµ ráº±ng...â€
    - Thay vÃ o Ä‘Ã³, hÃ£y viáº¿t theo phong cÃ¡ch **ngÆ°á»i Ä‘ang tá»± suy nghÄ© má»™t cÃ¡ch chá»§ quan**, cháº³ng háº¡n:
        - "TÃ´i tháº¥y trong luáº­t cÃ³ nháº¯c Ä‘áº¿n Ä‘áº§u tÆ°, nÃªn tÃ´i cho ráº±ng má»i hÃ¬nh thá»©c Ä‘áº§u tÆ° Ä‘á»u bá»‹ Ä‘iá»u chá»‰nh, ká»ƒ cáº£ Ä‘áº§u tÆ° báº¥t Ä‘á»™ng sáº£n."
        - "TÃ´i nghÄ© vÃ¬ luáº­t khÃ´ng nÃ³i rÃµ, nÃªn Ä‘iá»u Ä‘Ã³ khÃ´ng thuá»™c pháº¡m vi Ä‘iá»u chá»‰nh."
    
    ğŸ“š TÃ i liá»‡u phÃ¡p lÃ½:
    \"\"\"
    {relevant_doc}
    \"\"\"
    
    Tráº£ vá» dÆ°á»›i dáº¡ng JSON:
    {{
        "question": "...",
        "chosen_answer": "...",
        "chosen_reason": "...",
        "rejected_answer": "...",
        "rejected_reason": "..."
    }}
    """



    messages = [
        {"role": "user", "content": prompt}
    ]
    text = tokenizer.apply_chat_template(
        messages,
        tokenize=False,
        add_generation_prompt=True,
        enable_thinking=False # Switches between thinking and non-thinking modes. Default is True.
    )
    model_inputs = tokenizer([text], return_tensors="pt").to(model.device)
    
    # conduct text completion
    generated_ids = model.generate(
        **model_inputs,
        max_new_tokens=8024
    )
    output_ids = generated_ids[0][len(model_inputs.input_ids[0]):].tolist() 
    
    # parsing thinking content
    try:
        # rindex finding 151668 (</think>)
        index = len(output_ids) - output_ids[::-1].index(151668)
    except ValueError:
        index = 0
    
    content = tokenizer.decode(output_ids[index:], skip_special_tokens=True).strip("\n")
    return content
        
from datetime import datetime

def get_relevant(index):
    relevant_content = dataset['train'].select([index])['chunk']
    relevant_meta = dataset['train'].select([index])['metadata']
    

    issue_date = relevant_meta[0]['metadata']['IssueDate']
    formatted_date = f"ngÃ y {issue_date.day} thÃ¡ng {issue_date.month} nÄƒm {issue_date.year}"
    relevant = f"""
    Theo luáº­t sá»‘ {relevant_meta[0]['metadata']['DocIdentity']}, {relevant_meta[0]['metadata']['OrganName']} ban hÃ nh luáº­t {relevant_meta[0]['metadata']['DocName']}  vÃ o {formatted_date}:
    {relevant_content}
    """
    return relevant
    
import json
import re

def clean_json_block(text):
    # Loáº¡i bá» ```json vÃ  ```
    text = re.sub(r"^```json\n", "", text.strip())
    text = re.sub(r"\n```$", "", text.strip())
    return json.loads(text)

import random
import json
import argparse

# Setup logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('genqa_vlsp_track6.log'),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger(__name__)

# Parse command line arguments
parser = argparse.ArgumentParser(description='Generate QA data for VLSP track 6')
parser.add_argument('--start_index', type=int, default=0, help='Starting index for processing')
parser.add_argument('--end_index', type=int, default=None, help='Ending index for processing')
parser.add_argument('--single_index', type=int, default=None, help='Process single index')
args = parser.parse_args()

# Determine range to process
if args.single_index is not None:
    start_j = args.single_index
    end_j = args.single_index + 1
    output_path = f"output_{start_j}.json"
    logger.info(f"Processing single index: {args.single_index}")
elif args.end_index is not None:
    start_j = args.start_index
    end_j = args.end_index
    output_path = f"output_{start_j}_{end_j-1}.json"
    logger.info(f"Processing range: {start_j} to {end_j-1}")
else:
    start_j = args.start_index
    end_j = len(dataset['train'])
    output_path = f"output_{start_j}_end.json"
    logger.info(f"Processing from index {start_j} to end of dataset")

logger.info(f"Output will be saved to: {output_path}")

for j in range(start_j, end_j):
    logger.info(f"Processing document {j}/{end_j-1}")
    # 1. Láº¥y 1 Ä‘oáº¡n tÃ i liá»‡u chÃ­nh
    relevant1 = get_relevant(j)

    # 2. Sinh cÃ¢u há»i tá»« tÃ i liá»‡u chÃ­nh
    for i in range(3):
        if i == 0:
            task = "ÄÃ¡nh giÃ¡ tÃ­nh há»¯u Ã­ch cá»§a trÃ­ch dáº«n phÃ¡p luáº­t: XÃ¡c Ä‘á»‹nh liá»‡u má»™t trÃ­ch dáº«n phÃ¡p luáº­t cÃ³ há»¯u Ã­ch Ä‘á»ƒ tráº£ lá»i cÃ¢u há»i phÃ¡p lÃ½ hay khÃ´ng (phÃ¢n loáº¡i ÄÃºng/Sai)"
        elif i == 1:
            task = "CÃ¢u há»i tráº¯c nghiá»‡m phÃ¡p luáº­t: Kiá»ƒm tra kiáº¿n thá»©c phÃ¡p luáº­t Viá»‡t Nam thÃ´ng qua cÃ¡c cÃ¢u há»i tráº¯c nghiá»‡m nhiá»u lá»±a chá»n"
        else:
            task = "CÃ¢u há»i tá»± luáº­n phÃ¡p luáº­t: Sinh cÃ¢u tráº£ lá»i tá»± do, Ä‘áº§y Ä‘á»§ vÃ  máº¡ch láº¡c cho cÃ¡c cÃ¢u há»i phÃ¡p lÃ½ báº±ng tiáº¿ng Viá»‡t"

        qa_raw = gen_data(relevant1, task)
        if isinstance(qa_raw, str):
            try:
                qa = clean_json_block(qa_raw)
            except Exception as e:
                logger.error(f"âŒ Lá»—i parse JSON táº¡i index {j}, task: {task}: {e}")
                print(f"âŒ Lá»—i parse JSON táº¡i index {j}, task: {task}: {e}")
                continue
        else:
            qa = qa_raw
        # Ghi náº¿u há»£p lá»‡
        if isinstance(qa, dict):
            with open(output_path, "a", encoding="utf-8") as f:
                f.write(json.dumps(qa, ensure_ascii=False) + "\n")
   
    
    # 3. GhÃ©p thÃªm 1â€“3 tÃ i liá»‡u khÃ¡c
    relevant_str = relevant1 + "\n"
    list_num = []
    random_number_law = random.randint(1, 4)

    for _ in range(random_number_law):
        random_number = random.randint(0, len(dataset['train']) - 1)
        while random_number in list_num or random_number == j:
            random_number = random.randint(0, len(dataset['train']) - 1)

        list_num.append(random_number)
        relevant2 = get_relevant(random_number)
        relevant_str += relevant2 + "\n"

    # 4. Sinh cÃ¢u há»i tá»« Ä‘oáº¡n ghÃ©p
    for i in range(3):
        if i == 0:
            task = "ÄÃ¡nh giÃ¡ tÃ­nh há»¯u Ã­ch cá»§a trÃ­ch dáº«n phÃ¡p luáº­t: XÃ¡c Ä‘á»‹nh liá»‡u má»™t trÃ­ch dáº«n phÃ¡p luáº­t cÃ³ há»¯u Ã­ch Ä‘á»ƒ tráº£ lá»i cÃ¢u há»i phÃ¡p lÃ½ hay khÃ´ng (phÃ¢n loáº¡i ÄÃºng/Sai)"
        elif i == 1:
            task = "CÃ¢u há»i tráº¯c nghiá»‡m phÃ¡p luáº­t: Kiá»ƒm tra kiáº¿n thá»©c phÃ¡p luáº­t Viá»‡t Nam thÃ´ng qua cÃ¡c cÃ¢u há»i tráº¯c nghiá»‡m nhiá»u lá»±a chá»n"
        else:
            task = "CÃ¢u há»i tá»± luáº­n phÃ¡p luáº­t: Sinh cÃ¢u tráº£ lá»i tá»± do, Ä‘áº§y Ä‘á»§ vÃ  máº¡ch láº¡c cho cÃ¡c cÃ¢u há»i phÃ¡p lÃ½ báº±ng tiáº¿ng Viá»‡t"

        qa_raw = gen_data(relevant_str, task)
        if isinstance(qa_raw, str):
            try:
                qa = clean_json_block(qa_raw)
            except Exception as e:
                logger.error(f"âŒ Lá»—i parse JSON táº¡i index {j}, task: {task}: {e}")
                print(f"âŒ Lá»—i parse JSON táº¡i index {j}, task: {task}: {e}")
                continue
        else:
            qa = qa_raw
        # Ghi náº¿u há»£p lá»‡
        if isinstance(qa, dict):
            with open(output_path, "a", encoding="utf-8") as f:
                f.write(json.dumps(qa, ensure_ascii=False) + "\n")
   
    logger.info(f"âœ… ÄÃ£ sinh vÃ  ghi dá»¯ liá»‡u cho máº«u #{j}")
    print(f"âœ… ÄÃ£ sinh vÃ  ghi dá»¯ liá»‡u cho máº«u #{j}")