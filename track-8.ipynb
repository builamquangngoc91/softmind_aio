{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":12399525,"sourceType":"datasetVersion","datasetId":7819336}],"dockerImageVersionId":31041,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-07-07T13:21:58.945069Z","iopub.execute_input":"2025-07-07T13:21:58.945335Z","iopub.status.idle":"2025-07-07T13:21:59.208646Z","shell.execute_reply.started":"2025-07-07T13:21:58.945313Z","shell.execute_reply":"2025-07-07T13:21:59.208059Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport pytorch_lightning as L\nfrom torch.utils.data import Dataset, DataLoader, ConcatDataset\nfrom transformers import AutoTokenizer, AutoModel\nimport json\nimport re\nfrom datetime import datetime, timedelta\nfrom dateutil.relativedelta import relativedelta\nimport pandas as pd\nfrom sklearn.metrics import accuracy_score, precision_recall_fscore_support\nimport numpy as np\nfrom typing import Dict, List, Tuple, Optional\nimport warnings\nimport random\nimport traceback\nwarnings.filterwarnings('ignore')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-07T13:21:59.209870Z","iopub.execute_input":"2025-07-07T13:21:59.210141Z","iopub.status.idle":"2025-07-07T13:22:11.690500Z","shell.execute_reply.started":"2025-07-07T13:21:59.210123Z","shell.execute_reply":"2025-07-07T13:22:11.689658Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"class TemporalConfig:\n    def __init__(self):\n        # Model config\n        self.model_name = \"vinai/phobert-large\"\n        self.hidden_size = 768 \n        self.num_labels_duration = 2  # yes/no \n        self.max_length = 256\n        self.dropout = 0.1\n        \n        # Training config\n        self.learning_rate = 2e-5\n        self.weight_decay = 0.01\n        self.warmup_steps = 1000\n        self.batch_size = 16\n        self.num_epochs = 10\n        \n        # Task weights\n        self.date_weight = 1.0\n        self.duration_weight = 1.0\n        \n        # Device handling\n        self.device = 'cuda' if torch.cuda.is_available() else 'cpu'","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-07T13:22:11.691293Z","iopub.execute_input":"2025-07-07T13:22:11.691696Z","iopub.status.idle":"2025-07-07T13:22:11.696523Z","shell.execute_reply.started":"2025-07-07T13:22:11.691676Z","shell.execute_reply":"2025-07-07T13:22:11.695788Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"class DateArithmeticProcessor:    \n    def __init__(self):\n        self.month_mapping = {\n            'tháng 1': 1, 'tháng 2': 2, 'tháng 3': 3, 'tháng 4': 4,\n            'tháng 5': 5, 'tháng 6': 6, 'tháng 7': 7, 'tháng 8': 8,\n            'tháng 9': 9, 'tháng 10': 10, 'tháng 11': 11, 'tháng 12': 12\n        }\n        \n        self.time_units = {\n            'năm': 'years', 'tháng': 'months', 'ngày': 'days',\n            'tuần': 'weeks', 'giờ': 'hours', 'phút': 'minutes'\n        }\n    \n    def parse_vietnamese_date(self, date_str: str) -> datetime:\n        date_str = date_str.lower().strip()\n        \n        # \"tháng X, YYYY\"\n        pattern = r'tháng\\s+(\\d+),?\\s*(\\d{4})'\n        match = re.search(pattern, date_str)\n        if match:\n            month, year = int(match.group(1)), int(match.group(2))\n            return datetime(year, month, 1)\n        \n        raise ValueError(f\"Cannot parse date: {date_str}\")\n    \n    def parse_time_expression(self, text: str) -> Dict:\n        result = {}\n        \n        # Pattern cho số + đơn vị thời gian\n        patterns = {\n            'years': r'(\\d+)\\s*năm',\n            'months': r'(\\d+)\\s*tháng', \n            'days': r'(\\d+)\\s*ngày',\n            'weeks': r'(\\d+)\\s*tuần',\n            'hours': r'(\\d+)\\s*giờ',\n            'minutes': r'(\\d+)\\s*phút'\n        }\n        \n        for unit, pattern in patterns.items():\n            match = re.search(pattern, text)\n            if match:\n                result[unit] = int(match.group(1))\n        \n        return result\n    \n    def calculate_date(self, base_date: datetime, time_delta: Dict, operation: str) -> datetime:\n        delta_kwargs = {k: v for k, v in time_delta.items() if k in ['years', 'months', 'days', 'weeks', 'hours', 'minutes']}\n        \n        if operation == 'subtract':\n            for key in delta_kwargs:\n                delta_kwargs[key] = -delta_kwargs[key]\n        \n        if 'years' in delta_kwargs or 'months' in delta_kwargs:\n            years = delta_kwargs.pop('years', 0)\n            months = delta_kwargs.pop('months', 0)\n            new_date = base_date + relativedelta(years=years, months=months)\n            \n            if delta_kwargs:\n                td = timedelta(**delta_kwargs)\n                new_date += td\n        else:\n            td = timedelta(**delta_kwargs)\n            new_date = base_date + td\n        \n        return new_date\n    \n    def format_vietnamese_date(self, date: datetime) -> str:\n        return f\"Tháng {date.month}, {date.year}\"\n    \n    def process_question(self, question: str) -> str:\n        try:\n            question = question.lower()\n            \n            if 'trước' in question:\n                operation = 'subtract'\n            elif 'sau' in question:\n                operation = 'add'\n            else:\n                operation = 'add'  # default\n            \n            date_match = re.search(r'tháng\\s+(\\d+),?\\s*(\\d{4})', question)\n            if date_match:\n                base_date = self.parse_vietnamese_date(date_match.group(0))\n            else:\n                raise ValueError(\"Cannot find base date\")\n            \n            time_delta = self.parse_time_expression(question)\n            \n            result_date = self.calculate_date(base_date, time_delta, operation)\n            \n            return self.format_vietnamese_date(result_date)\n            \n        except Exception as e:\n            print(f\"Error processing question: {question}, Error: {e}\")\n            return \"Tháng 1, 2000\"  # fallback","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-07T13:22:11.698263Z","iopub.execute_input":"2025-07-07T13:22:11.698543Z","iopub.status.idle":"2025-07-07T13:22:11.738453Z","shell.execute_reply.started":"2025-07-07T13:22:11.698525Z","shell.execute_reply":"2025-07-07T13:22:11.737781Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"class TemporalDataset(Dataset):\n    \n    def __init__(self, data: List[Dict], tokenizer, config: TemporalConfig, task_type: str):\n        self.data = data\n        self.tokenizer = tokenizer\n        self.config = config\n        self.task_type = task_type\n        self.date_processor = DateArithmeticProcessor()\n        \n        self._validate_data()\n    \n    def _validate_data(self):\n        \"\"\"Validate and clean data\"\"\"\n        valid_data = []\n        for i, item in enumerate(self.data):\n            try:\n                if self.task_type == 'date_arithmetic':\n                    if 'question' in item and 'answer' in item:\n                        valid_data.append(item)\n                    else:\n                        if i < 5:\n                            print(f\"Skipping date item {i}: missing 'question' or 'answer'\")\n                else:\n                    required_fields = ['context', 'question', 'options', 'labels']\n                    if all(field in item for field in required_fields):\n                        if isinstance(item['options'], list) and isinstance(item['labels'], list):\n                            if len(item['options']) == len(item['labels']):\n                                valid_data.append(item)\n                            else:\n                                if i < 5:\n                                    print(f\"Skipping duration item {i}: options and labels length mismatch\")\n                        else:\n                            if i < 5:\n                                print(f\"Skipping duration item {i}: options or labels not lists\")\n                    else:\n                        missing_fields = [f for f in required_fields if f not in item]\n                        if i < 5:\n                            print(f\"Skipping duration item {i}: missing fields {missing_fields}\")\n            except Exception as e:\n                if i < 5:\n                    print(f\"Error validating item {i}: {e}\")\n        \n        print(f\"Validated {len(valid_data)}/{len(self.data)} items for {self.task_type}\")\n        self.data = valid_data\n    \n    def __len__(self):\n        return len(self.data)\n    \n    def __getitem__(self, idx):\n        try:\n            item = self.data[idx]\n            \n            if self.task_type == 'date_arithmetic':\n                return self._process_date_arithmetic(item)\n            else:\n                return self._process_duration_qa(item)\n        except Exception as e:\n            print(f\"Error processing item {idx}: {e}\")\n            return self._get_dummy_item()\n    \n    def _get_dummy_item(self):\n        if self.task_type == 'date_arithmetic':\n            dummy_question = \"Thời gian 1 năm trước tháng 1, 2000 là khi nào?\"\n            dummy_answer = \"Tháng 1, 1999\"\n            \n            encoding = self.tokenizer(\n                dummy_question,\n                padding='max_length',\n                truncation=True,\n                max_length=self.config.max_length,\n                return_tensors='pt'\n            )\n            \n            target_encoding = self.tokenizer(\n                dummy_answer,\n                padding='max_length',\n                truncation=True,\n                max_length=64,\n                return_tensors='pt'\n            )\n            \n            return {\n                'input_ids': encoding['input_ids'].squeeze(),\n                'attention_mask': encoding['attention_mask'].squeeze(),\n                'target_ids': target_encoding['input_ids'].squeeze(),\n                'target_attention_mask': target_encoding['attention_mask'].squeeze(),\n                'question': dummy_question,\n                'answer': dummy_answer\n            }\n        else:  # duration_qa\n            dummy_context = \"Dummy context\"\n            dummy_question = \"Dummy question\"\n            dummy_options = [\"Option 1\", \"Option 2\"]\n            dummy_labels = [\"yes\", \"no\"]\n            \n            batch_data = []\n            for i, (option, label) in enumerate(zip(dummy_options, dummy_labels)):\n                full_input = f\"{dummy_context} [SEP] {dummy_question} [SEP] {option}\"\n                \n                encoding = self.tokenizer(\n                    full_input,\n                    padding='max_length',\n                    truncation=True,\n                    max_length=self.config.max_length,\n                    return_tensors='pt'\n                )\n                \n                label_int = 1 if label == 'yes' else 0\n                \n                batch_data.append({\n                    'input_ids': encoding['input_ids'].squeeze(),\n                    'attention_mask': encoding['attention_mask'].squeeze(),\n                    'label': torch.tensor(label_int, dtype=torch.long),\n                    'option_idx': i\n                })\n            \n            return {\n                'options_data': batch_data,\n                'qid': 0,\n                'context': dummy_context,\n                'question': dummy_question,\n                'options': dummy_options,\n                'labels': dummy_labels\n            }\n    \n    def _process_date_arithmetic(self, item):\n        question = item['question']\n        answer = item['answer'][0] if isinstance(item['answer'], list) else item['answer']\n        \n        # Tokenize input\n        encoding = self.tokenizer(\n            question,\n            padding='max_length',\n            truncation=True,\n            max_length=self.config.max_length,\n            return_tensors='pt'\n        )\n        \n        # Tokenize target\n        target_encoding = self.tokenizer(\n            answer,\n            padding='max_length',\n            truncation=True,\n            max_length=64,\n            return_tensors='pt'\n        )\n        \n        return {\n            'input_ids': encoding['input_ids'].squeeze(),\n            'attention_mask': encoding['attention_mask'].squeeze(),\n            'target_ids': target_encoding['input_ids'].squeeze(),\n            'target_attention_mask': target_encoding['attention_mask'].squeeze(),\n            'question': question,\n            'answer': answer\n        }\n    \n    def _process_duration_qa(self, item):\n        context = item['context']\n        question = item['question'] \n        options = item['options']\n        labels = item['labels']\n        qid = item.get('qid', 0)\n        \n        # Combine context + question\n        input_text = f\"{context} [SEP] {question}\"\n        \n        batch_data = []\n        for i, (option, label) in enumerate(zip(options, labels)):\n            # Combine input với từng option\n            full_input = f\"{input_text} [SEP] {option}\"\n            \n            encoding = self.tokenizer(\n                full_input,\n                padding='max_length',\n                truncation=True,\n                max_length=self.config.max_length,\n                return_tensors='pt'\n            )\n            \n            # Convert yes/no to 1/0\n            label_int = 1 if label == 'yes' else 0\n            \n            batch_data.append({\n                'input_ids': encoding['input_ids'].squeeze(),\n                'attention_mask': encoding['attention_mask'].squeeze(),\n                'label': torch.tensor(label_int, dtype=torch.long),\n                'option_idx': i\n            })\n        \n        return {\n            'options_data': batch_data,\n            'qid': qid,\n            'context': context,\n            'question': question,\n            'options': options,\n            'labels': labels\n        }","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-07T13:22:11.739249Z","iopub.execute_input":"2025-07-07T13:22:11.739500Z","iopub.status.idle":"2025-07-07T13:22:11.758161Z","shell.execute_reply.started":"2025-07-07T13:22:11.739475Z","shell.execute_reply":"2025-07-07T13:22:11.757567Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"class TemporalModel(nn.Module):    \n    def __init__(self, config: TemporalConfig):\n        super().__init__()\n        self.config = config\n        \n        # Shared encoder\n        self.encoder = AutoModel.from_pretrained(config.model_name)\n        \n        actual_hidden_size = self.encoder.config.hidden_size\n        print(f\"Loaded model hidden size: {actual_hidden_size}\")\n        \n        if actual_hidden_size != config.hidden_size:\n            print(f\"Updating hidden_size from {config.hidden_size} to {actual_hidden_size}\")\n            config.hidden_size = actual_hidden_size\n        \n        # Task-specific heads\n        self.date_decoder = nn.TransformerDecoder(\n            nn.TransformerDecoderLayer(\n                d_model=config.hidden_size,\n                nhead=8,\n                dropout=config.dropout,\n                batch_first=True\n            ),\n            num_layers=3\n        )\n        \n        self.date_output = nn.Linear(config.hidden_size, self.encoder.config.vocab_size)\n        \n        self.duration_classifier = nn.Sequential(\n            nn.Linear(config.hidden_size, config.hidden_size // 2),\n            nn.ReLU(),\n            nn.Dropout(config.dropout),\n            nn.Linear(config.hidden_size // 2, config.num_labels_duration)\n        )\n        \n        self.dropout = nn.Dropout(config.dropout)\n    \n    def forward(self, input_ids, attention_mask, task_type, target_ids=None, target_attention_mask=None):\n        device = next(self.parameters()).device\n        input_ids = input_ids.to(device)\n        attention_mask = attention_mask.to(device)\n        \n        if target_ids is not None:\n            target_ids = target_ids.to(device)\n        if target_attention_mask is not None:\n            target_attention_mask = target_attention_mask.to(device)\n        \n        # Encode input\n        encoder_outputs = self.encoder(input_ids=input_ids, attention_mask=attention_mask)\n        encoded = encoder_outputs.last_hidden_state\n        pooled = encoder_outputs.pooler_output\n        \n        if task_type == 'date_arithmetic':\n            return self._forward_date_arithmetic(encoded, target_ids, target_attention_mask)\n        else:\n            return self._forward_duration_qa(pooled)\n    \n    def _forward_date_arithmetic(self, encoded, target_ids=None, target_attention_mask=None):\n        if target_ids is not None:\n            target_embedded = self.encoder.embeddings(target_ids)\n            memory = encoded\n            tgt = target_embedded\n            \n            # Create target mask for causal attention\n            tgt_len = tgt.size(1)\n            tgt_mask = torch.triu(torch.ones(tgt_len, tgt_len, device=tgt.device), diagonal=1).bool()\n            \n            decoded = self.date_decoder(tgt, memory, tgt_mask=tgt_mask)\n            logits = self.date_output(decoded)\n            return logits\n        else:\n            pooled = encoded.mean(dim=1)\n            logits = self.date_output(pooled).unsqueeze(1)\n            return logits\n    \n    def _forward_duration_qa(self, pooled):\n        pooled = self.dropout(pooled)\n        logits = self.duration_classifier(pooled)\n        return logits","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-07T13:22:11.758886Z","iopub.execute_input":"2025-07-07T13:22:11.759126Z","iopub.status.idle":"2025-07-07T13:22:11.774389Z","shell.execute_reply.started":"2025-07-07T13:22:11.759102Z","shell.execute_reply":"2025-07-07T13:22:11.773780Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"class TemporalTrainer(L.LightningModule):    \n    def __init__(self, config: TemporalConfig):\n        super().__init__()\n        self.config = config\n        self.save_hyperparameters()\n        \n        self.model = TemporalModel(config)\n        self.tokenizer = AutoTokenizer.from_pretrained(config.model_name)\n        \n        special_tokens = ['[SEP]']\n        self.tokenizer.add_tokens(special_tokens)\n        self.model.encoder.resize_token_embeddings(len(self.tokenizer))\n        \n        if self.tokenizer.pad_token is None:\n            self.tokenizer.pad_token = self.tokenizer.eos_token\n        \n        self.date_processor = DateArithmeticProcessor()\n        \n        self.train_losses = []\n        self.val_losses = []\n    \n    def forward(self, batch, task_type):\n        if task_type == 'date_arithmetic':\n            return self.model(\n                input_ids=batch['input_ids'],\n                attention_mask=batch['attention_mask'],\n                task_type=task_type,\n                target_ids=batch['target_ids'],\n                target_attention_mask=batch['target_attention_mask']\n            )\n        else:\n            return self.model(\n                input_ids=batch['input_ids'],\n                attention_mask=batch['attention_mask'],\n                task_type=task_type\n            )\n    \n    def _compute_date_loss(self, batch):\n        try:\n            logits = self.forward(batch, 'date_arithmetic')\n            \n            shift_logits = logits[..., :-1, :].contiguous()\n            shift_labels = batch['target_ids'][..., 1:].contiguous()\n            \n            pad_token_id = self.tokenizer.pad_token_id if self.tokenizer.pad_token_id is not None else -100\n            \n            loss = F.cross_entropy(\n                shift_logits.view(-1, shift_logits.size(-1)),\n                shift_labels.view(-1),\n                ignore_index=pad_token_id\n            )\n            return loss\n        except Exception as e:\n            print(f\"Error in date loss computation: {e}\")\n            return torch.tensor(0.0, requires_grad=True, device=self.device)\n    \n    def _compute_duration_loss(self, batch):\n        try:\n            total_loss = 0\n            batch_size = len(batch['options_data'])\n            \n            if batch_size == 0:\n                return torch.tensor(0.0, requires_grad=True, device=self.device)\n            \n            for i in range(batch_size):\n                options_data = batch['options_data'][i]\n                \n                input_ids = torch.stack([opt['input_ids'] for opt in options_data])\n                attention_mask = torch.stack([opt['attention_mask'] for opt in options_data])\n                labels = torch.stack([opt['label'] for opt in options_data])\n                \n                logits = self.model(\n                    input_ids=input_ids,\n                    attention_mask=attention_mask,\n                    task_type='duration_qa'\n                )\n                \n                loss = F.cross_entropy(logits, labels)\n                total_loss += loss\n            \n            return total_loss / batch_size\n        except Exception as e:\n            print(f\"Error in duration loss computation: {e}\")\n            return torch.tensor(0.0, requires_grad=True, device=self.device)\n    \n    def training_step(self, batch, batch_idx):\n        total_loss = 0\n        loss_count = 0\n        \n        try:\n            if 'date_batch' in batch and batch['date_batch'] is not None:\n                date_loss = self._compute_date_loss(batch['date_batch'])\n                total_loss += date_loss * self.config.date_weight\n                loss_count += 1\n                self.log('train_date_loss', date_loss, prog_bar=True)\n            \n            if 'duration_batch' in batch and batch['duration_batch'] is not None:\n                duration_loss = self._compute_duration_loss(batch['duration_batch'])\n                total_loss += duration_loss * self.config.duration_weight\n                loss_count += 1\n                self.log('train_duration_loss', duration_loss, prog_bar=True)\n            \n            if loss_count == 0:\n                task_type = batch.get('task_type', 'date_arithmetic')\n                if task_type == 'date_arithmetic':\n                    total_loss = self._compute_date_loss(batch)\n                    self.log('train_date_loss', total_loss, prog_bar=True)\n                else:\n                    total_loss = self._compute_duration_loss(batch)\n                    self.log('train_duration_loss', total_loss, prog_bar=True)\n                loss_count = 1\n            \n            if loss_count > 0:\n                total_loss = total_loss / loss_count\n            else:\n                total_loss = torch.tensor(0.0, requires_grad=True, device=self.device)\n            \n            self.log('train_loss', total_loss, prog_bar=True)\n            return total_loss\n            \n        except Exception as e:\n            print(f\"Training step error: {e}\")\n            return torch.tensor(0.0, requires_grad=True, device=self.device)\n    \n    def validation_step(self, batch, batch_idx, dataloader_idx=0):\n        try:\n            if dataloader_idx == 0:\n                if 'date_batch' in batch:\n                    return self._validate_date_batch(batch['date_batch'])\n                else:\n                    return self._validate_date_batch(batch)\n            else:  # Duration QA\n                if 'duration_batch' in batch:\n                    return self._validate_duration_batch(batch['duration_batch'])\n                else:\n                    return self._validate_duration_batch(batch)\n            \n        except Exception as e:\n            print(f\"Validation step error: {e}\")\n            return torch.tensor(0.0, device=self.device)\n    \n    def _validate_date_batch(self, batch):\n        loss = self._compute_date_loss(batch)\n        \n        with torch.no_grad():\n            predictions = self.generate_date_answers(batch)\n            targets = batch['answer']\n            \n            exact_matches = sum(1 for pred, target in zip(predictions, targets) \n                              if pred.strip().lower() == target.strip().lower())\n            accuracy = exact_matches / len(predictions) if len(predictions) > 0 else 0.0\n        \n        self.log('val_date_loss', loss, prog_bar=True, add_dataloader_idx=False)\n        self.log('val_date_accuracy', accuracy, prog_bar=True, add_dataloader_idx=False)\n        return loss\n    \n    def _validate_duration_batch(self, batch):\n        loss = self._compute_duration_loss(batch)\n        \n        with torch.no_grad():\n            predictions, targets = self.predict_duration_labels(batch)\n            \n            if len(predictions) > 0 and len(targets) > 0:\n                exact_matches = sum(1 for pred, target in zip(predictions, targets)\n                                  if pred == target)\n                exact_match = exact_matches / len(predictions)\n                self.log('val_duration_exact_match', exact_match, prog_bar=True, add_dataloader_idx=False)\n        \n        self.log('val_duration_loss', loss, prog_bar=True, add_dataloader_idx=False)\n        return loss\n    \n    def test_step(self, batch, batch_idx, dataloader_idx=0):\n        try:\n            if dataloader_idx == 0:  # Date arithmetic\n                if 'date_batch' in batch:\n                    batch = batch['date_batch']\n                \n                loss = self._compute_date_loss(batch)\n                \n                with torch.no_grad():\n                    predictions = self.generate_date_answers(batch)\n                    targets = batch['answer']\n                    \n                    exact_matches = sum(1 for pred, target in zip(predictions, targets) \n                                      if pred.strip().lower() == target.strip().lower())\n                    accuracy = exact_matches / len(predictions) if len(predictions) > 0 else 0.0\n                \n                self.log('test_date_loss', loss, prog_bar=True, add_dataloader_idx=False)\n                self.log('test_date_accuracy', accuracy, prog_bar=True, add_dataloader_idx=False)\n                \n            else:  # Duration QA\n                if 'duration_batch' in batch:\n                    batch = batch['duration_batch']\n                \n                loss = self._compute_duration_loss(batch)\n                \n                with torch.no_grad():\n                    predictions, targets = self.predict_duration_labels(batch)\n                    \n                    if len(predictions) > 0 and len(targets) > 0:\n                        exact_matches = sum(1 for pred, target in zip(predictions, targets)\n                                          if pred == target)\n                        exact_match = exact_matches / len(predictions)\n                        \n                        all_preds = [item for sublist in predictions for item in sublist]\n                        all_targets = [item for sublist in targets for item in sublist]\n                        \n                        if len(all_preds) > 0 and len(all_targets) > 0:\n                            precision, recall, f1, _ = precision_recall_fscore_support(\n                                all_targets, all_preds, average='binary', zero_division=0\n                            )\n                            accuracy = accuracy_score(all_targets, all_preds)\n                        else:\n                            precision = recall = f1 = accuracy = 0.0\n                    else:\n                        exact_match = precision = recall = f1 = accuracy = 0.0\n                \n                self.log('test_duration_loss', loss, prog_bar=True, add_dataloader_idx=False)\n                self.log('test_duration_exact_match', exact_match, prog_bar=True, add_dataloader_idx=False)\n                self.log('test_duration_accuracy', accuracy, prog_bar=True, add_dataloader_idx=False)\n                self.log('test_duration_precision', precision, prog_bar=True, add_dataloader_idx=False)\n                self.log('test_duration_recall', recall, prog_bar=True, add_dataloader_idx=False)\n                self.log('test_duration_f1', f1, prog_bar=True, add_dataloader_idx=False)\n            \n            return loss\n            \n        except Exception as e:\n            print(f\"Test step error: {e}\")\n            return torch.tensor(0.0, device=self.device)\n    \n    def generate_date_answers(self, batch):\n        self.model.eval()\n        predictions = []\n        \n        with torch.no_grad():\n            for i in range(len(batch['question'])):\n                question = batch['question'][i]\n                pred = self.date_processor.process_question(question)\n                predictions.append(pred)\n        \n        return predictions\n    \n    def predict_duration_labels(self, batch):\n        self.model.eval()\n        predictions = []\n        targets = []\n        \n        with torch.no_grad():\n            batch_size = len(batch['options_data'])\n            \n            for i in range(batch_size):\n                options_data = batch['options_data'][i]\n                \n                input_ids = torch.stack([opt['input_ids'] for opt in options_data])\n                attention_mask = torch.stack([opt['attention_mask'] for opt in options_data])\n                true_labels = [opt['label'].item() for opt in options_data]\n                \n                logits = self.model(\n                    input_ids=input_ids,\n                    attention_mask=attention_mask,\n                    task_type='duration_qa'\n                )\n                \n                predicted_labels = torch.argmax(logits, dim=1).cpu().tolist()\n                \n                predictions.append(predicted_labels)\n                targets.append(true_labels)\n        \n        return predictions, targets\n    \n    def configure_optimizers(self):\n        optimizer = torch.optim.AdamW(\n            self.parameters(),\n            lr=self.config.learning_rate,\n            weight_decay=self.config.weight_decay\n        )\n        \n        scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(\n            optimizer, T_max=self.config.num_epochs\n        )\n        \n        return [optimizer], [scheduler]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-07T13:22:11.775276Z","iopub.execute_input":"2025-07-07T13:22:11.775523Z","iopub.status.idle":"2025-07-07T13:22:11.804317Z","shell.execute_reply.started":"2025-07-07T13:22:11.775502Z","shell.execute_reply":"2025-07-07T13:22:11.803595Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"class MultiTaskDataModule(L.LightningDataModule):    \n    def __init__(self, config: TemporalConfig, date_train_path: str, duration_train_path: str):\n        super().__init__()\n        self.config = config\n        self.date_train_path = date_train_path\n        self.duration_train_path = duration_train_path\n        \n        self.tokenizer = AutoTokenizer.from_pretrained(config.model_name)\n        special_tokens = ['[SEP]']\n        self.tokenizer.add_tokens(special_tokens)\n        \n        if self.tokenizer.pad_token is None:\n            self.tokenizer.pad_token = self.tokenizer.eos_token\n    \n    def setup(self, stage=None):\n        print(\"Loading and splitting data...\")\n        \n        date_data = self.load_data(self.date_train_path, 'date')\n        duration_data = self.load_data(self.duration_train_path, 'duration')\n        \n        date_train, date_val, date_test = self.split_data_three_way(date_data, 0.7, 0.15, 0.15)\n        duration_train, duration_val, duration_test = self.split_data_three_way(duration_data, 0.7, 0.15, 0.15)\n        \n        self.date_train_dataset = TemporalDataset(date_train, self.tokenizer, self.config, 'date_arithmetic')\n        self.date_val_dataset = TemporalDataset(date_val, self.tokenizer, self.config, 'date_arithmetic')\n        self.date_test_dataset = TemporalDataset(date_test, self.tokenizer, self.config, 'date_arithmetic')\n        \n        self.duration_train_dataset = TemporalDataset(duration_train, self.tokenizer, self.config, 'duration_qa')\n        self.duration_val_dataset = TemporalDataset(duration_val, self.tokenizer, self.config, 'duration_qa')\n        self.duration_test_dataset = TemporalDataset(duration_test, self.tokenizer, self.config, 'duration_qa')\n        \n        print(f\"\\n=== Data Statistics ===\")\n        print(f\"Date Arithmetic - Train: {len(date_train)}, Val: {len(date_val)}, Test: {len(date_test)}\")\n        print(f\"Duration QA - Train: {len(duration_train)}, Val: {len(duration_val)}, Test: {len(duration_test)}\")\n    \n    def load_data(self, file_path: str, data_type: str) -> List[Dict]:\n        data = []\n        try:\n            print(f\"Loading {data_type} data from {file_path}\")\n            with open(file_path, 'r', encoding='utf-8') as f:\n                for line_num, line in enumerate(f, 1):\n                    line = line.strip()\n                    if not line:\n                        continue\n                    try:\n                        item = json.loads(line)\n                        data.append(item)\n                    except json.JSONDecodeError as e:\n                        if line_num <= 5:  # Only show first few errors\n                            print(f\"JSON error in line {line_num}: {e}\")\n                        continue\n            \n            print(f\"Successfully loaded {len(data)} {data_type} items\")\n            \n        except FileNotFoundError:\n            print(f\"File {file_path} not found! Creating dummy data...\")\n            if data_type == 'date':\n                data = [\n                    {\"question\": \"Thời gian 1 năm trước tháng 6, 1297 là khi nào?\", \"answer\": [\"Tháng 6, 1296\"]},\n                    {\"question\": \"Thời gian 2 tháng sau tháng 3, 1400 là khi nào?\", \"answer\": [\"Tháng 5, 1400\"]},\n                    {\"question\": \"Thời gian 6 tháng trước tháng 12, 1500 là khi nào?\", \"answer\": [\"Tháng 6, 1500\"]},\n                ]\n            else:  # duration\n                data = [\n                    {\"context\": \"Tôi nấu cơm.\", \"question\": \"Mất bao lâu để nấu cơm?\", \"options\": [\"30 phút\", \"2 giờ\"], \"labels\": [\"yes\", \"no\"], \"qid\": 1},\n                    {\"context\": \"Anh ấy du lịch.\", \"question\": \"Chuyến đi kéo dài bao lâu?\", \"options\": [\"1 ngày\", \"1 tuần\"], \"labels\": [\"no\", \"yes\"], \"qid\": 2},\n                    {\"context\": \"Cô ấy học tiếng Anh.\", \"question\": \"Cô ấy học trong bao lâu?\", \"options\": [\"1 tháng\", \"2 năm\"], \"labels\": [\"no\", \"yes\"], \"qid\": 3},\n                ]\n        except Exception as e:\n            print(f\"Error loading {file_path}: {e}\")\n            data = []\n        \n        return data\n    \n    def split_data_three_way(self, data: List[Dict], train_ratio: float, val_ratio: float, test_ratio: float):\n        if len(data) == 0:\n            return [], [], []\n        \n        random.shuffle(data)\n        \n        total = train_ratio + val_ratio + test_ratio\n        train_ratio /= total\n        val_ratio /= total\n        \n        n = len(data)\n        train_end = max(1, int(n * train_ratio))\n        val_end = max(train_end + 1, train_end + max(1, int(n * val_ratio)))\n        \n        train_data = data[:train_end]\n        val_data = data[train_end:val_end] if val_end > train_end else data[:1]\n        test_data = data[val_end:] if val_end < n else data[:1]\n        \n        return train_data, val_data, test_data\n    \n    def collate_fn_mixed(self, batch):\n        try:\n            batch = [item for item in batch if item is not None]\n            if not batch:\n                return None\n            \n            # Separate by task type\n            date_items = [item for item in batch if 'target_ids' in item]\n            duration_items = [item for item in batch if 'options_data' in item]\n            \n            result = {}\n            \n            if date_items:\n                result['date_batch'] = {\n                    'input_ids': torch.stack([item['input_ids'] for item in date_items]),\n                    'attention_mask': torch.stack([item['attention_mask'] for item in date_items]),\n                    'target_ids': torch.stack([item['target_ids'] for item in date_items]),\n                    'target_attention_mask': torch.stack([item['target_attention_mask'] for item in date_items]),\n                    'question': [item['question'] for item in date_items],\n                    'answer': [item['answer'] for item in date_items],\n                    'task_type': 'date_arithmetic'\n                }\n            \n            if duration_items:\n                result['duration_batch'] = {\n                    'options_data': [item['options_data'] for item in duration_items],\n                    'qid': [item['qid'] for item in duration_items],\n                    'context': [item['context'] for item in duration_items],\n                    'question': [item['question'] for item in duration_items],\n                    'options': [item['options'] for item in duration_items],\n                    'labels': [item['labels'] for item in duration_items],\n                    'task_type': 'duration_qa'\n                }\n            \n            return result\n            \n        except Exception as e:\n            print(f\"Error in mixed collate: {e}\")\n            return None\n    \n    def collate_fn_date(self, batch):\n        try:\n            batch = [item for item in batch if item is not None]\n            if not batch:\n                return None\n            \n            return {\n                'input_ids': torch.stack([item['input_ids'] for item in batch]),\n                'attention_mask': torch.stack([item['attention_mask'] for item in batch]),\n                'target_ids': torch.stack([item['target_ids'] for item in batch]),\n                'target_attention_mask': torch.stack([item['target_attention_mask'] for item in batch]),\n                'question': [item['question'] for item in batch],\n                'answer': [item['answer'] for item in batch],\n                'task_type': 'date_arithmetic'\n            }\n        except Exception as e:\n            print(f\"Error in date collate: {e}\")\n            return None\n    \n    def collate_fn_duration(self, batch):\n        try:\n            batch = [item for item in batch if item is not None]\n            if not batch:\n                return None\n            \n            return {\n                'options_data': [item['options_data'] for item in batch],\n                'qid': [item['qid'] for item in batch],\n                'context': [item['context'] for item in batch],\n                'question': [item['question'] for item in batch],\n                'options': [item['options'] for item in batch],\n                'labels': [item['labels'] for item in batch],\n                'task_type': 'duration_qa'\n            }\n        except Exception as e:\n            print(f\"Error in duration collate: {e}\")\n            return None\n    \n    def train_dataloader(self):\n        combined_dataset = ConcatDataset([self.date_train_dataset, self.duration_train_dataset])\n        \n        return DataLoader(\n            combined_dataset,\n            batch_size=self.config.batch_size,\n            shuffle=True,\n            collate_fn=self.collate_fn_mixed,\n            num_workers=0,\n            pin_memory=True,\n            drop_last=True\n        )\n    \n    def val_dataloader(self):\n        date_loader = DataLoader(\n            self.date_val_dataset,\n            batch_size=self.config.batch_size,\n            shuffle=False,\n            collate_fn=self.collate_fn_date,\n            num_workers=0,\n            pin_memory=True\n        )\n        \n        duration_loader = DataLoader(\n            self.duration_val_dataset,\n            batch_size=self.config.batch_size,\n            shuffle=False,\n            collate_fn=self.collate_fn_duration,\n            num_workers=0,\n            pin_memory=True\n        )\n        \n        return [date_loader, duration_loader]\n    \n    def test_dataloader(self):\n        date_loader = DataLoader(\n            self.date_test_dataset,\n            batch_size=self.config.batch_size,\n            shuffle=False,\n            collate_fn=self.collate_fn_date,\n            num_workers=0,\n            pin_memory=True\n        )\n        \n        duration_loader = DataLoader(\n            self.duration_test_dataset,\n            batch_size=self.config.batch_size,\n            shuffle=False,\n            collate_fn=self.collate_fn_duration,\n            num_workers=0,\n            pin_memory=True\n        )\n        \n        return [date_loader, duration_loader]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-07T13:22:11.805196Z","iopub.execute_input":"2025-07-07T13:22:11.805437Z","iopub.status.idle":"2025-07-07T13:22:11.829675Z","shell.execute_reply.started":"2025-07-07T13:22:11.805421Z","shell.execute_reply":"2025-07-07T13:22:11.829154Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def inference_date_arithmetic(model, question: str):\n    model.eval()\n    processor = DateArithmeticProcessor()\n    \n    with torch.no_grad():\n        answer = processor.process_question(question)\n        return answer","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-07T13:22:11.830310Z","iopub.execute_input":"2025-07-07T13:22:11.830546Z","iopub.status.idle":"2025-07-07T13:22:11.842866Z","shell.execute_reply.started":"2025-07-07T13:22:11.830530Z","shell.execute_reply":"2025-07-07T13:22:11.842230Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def inference_duration_qa(model, context: str, question: str, options: List[str]):\n    model.eval()\n    tokenizer = model.tokenizer\n    device = next(model.model.parameters()).device\n    \n    input_text = f\"{context} [SEP] {question}\"\n    predictions = []\n    \n    with torch.no_grad():\n        for option in options:\n            full_input = f\"{input_text} [SEP] {option}\"\n            \n            encoding = tokenizer(\n                full_input,\n                padding='max_length',\n                truncation=True,\n                max_length=256,\n                return_tensors='pt'\n            )\n            \n            encoding = {k: v.to(device) for k, v in encoding.items()}\n            \n            try:\n                logits = model.model(\n                    input_ids=encoding['input_ids'],\n                    attention_mask=encoding['attention_mask'],\n                    task_type='duration_qa'\n                )\n                \n                prob = torch.softmax(logits, dim=-1)[0, 1].item()\n                predictions.append(\"yes\" if prob > 0.5 else \"no\")\n                \n            except Exception as e:\n                print(f\"Error in inference: {e}\")\n                predictions.append(\"no\")\n    \n    return predictions","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-07T13:22:11.844367Z","iopub.execute_input":"2025-07-07T13:22:11.844568Z","iopub.status.idle":"2025-07-07T13:22:11.855050Z","shell.execute_reply.started":"2025-07-07T13:22:11.844553Z","shell.execute_reply":"2025-07-07T13:22:11.854462Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def evaluate_model(model, test_data_path: str, task_type: str):\n    with open(test_data_path, 'r', encoding='utf-8') as f:\n        test_data = [json.loads(line.strip()) for line in f]\n    \n    if task_type == 'date_arithmetic':\n        correct = 0\n        total = len(test_data)\n        \n        for item in test_data:\n            question = item['question']\n            true_answer = item['answer'][0] if isinstance(item['answer'], list) else item['answer']\n            \n            pred_answer = inference_date_arithmetic(model, question)\n            \n            if pred_answer.strip().lower() == true_answer.strip().lower():\n                correct += 1\n        \n        accuracy = correct / total\n        print(f\"Date Arithmetic Accuracy: {accuracy:.4f}\")\n        return accuracy\n    \n    else:  # duration_qa\n        exact_matches = 0\n        all_predictions = []\n        all_targets = []\n        \n        for item in test_data:\n            context = item['context']\n            question = item['question']\n            options = item['options']\n            true_labels = item['labels']\n            \n            pred_labels = inference_duration_qa(model, context, question, options)\n            \n            if pred_labels == true_labels:\n                exact_matches += 1\n            \n            # For precision/recall/f1\n            pred_binary = [1 if label == 'yes' else 0 for label in pred_labels]\n            true_binary = [1 if label == 'yes' else 0 for label in true_labels]\n            \n            all_predictions.extend(pred_binary)\n            all_targets.extend(true_binary)\n        \n        exact_match = exact_matches / len(test_data)\n        precision, recall, f1, _ = precision_recall_fscore_support(\n            all_targets, all_predictions, average='binary', zero_division=0\n        )\n        \n        print(f\"Duration QA - Exact Match: {exact_match:.4f}\")\n        print(f\"Duration QA - Precision: {precision:.4f}\")\n        print(f\"Duration QA - Recall: {recall:.4f}\")\n        print(f\"Duration QA - F1: {f1:.4f}\")\n        \n        return {\n            'exact_match': exact_match,\n            'precision': precision,\n            'recall': recall,\n            'f1': f1\n        }","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-07T13:22:11.855610Z","iopub.execute_input":"2025-07-07T13:22:11.855843Z","iopub.status.idle":"2025-07-07T13:22:11.867203Z","shell.execute_reply.started":"2025-07-07T13:22:11.855827Z","shell.execute_reply":"2025-07-07T13:22:11.866653Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def train_temporal_model_full():\n    try:\n        # Enhanced config\n        config = TemporalConfig()\n        config.batch_size = 4\n        config.num_epochs = 20\n        config.learning_rate = 2e-5\n        config.max_length = 256\n        config.date_weight = 1.0\n        config.duration_weight = 1.0\n        \n        print(f\"Using device: {config.device}\")\n        print(f\"Training config: {config.num_epochs} epochs, batch size {config.batch_size}\")\n        \n        # Data paths\n        date_train_path = \"/kaggle/input/track-8-temporal-qa/date_training_dataset.txt\"\n        duration_train_path = \"/kaggle/input/track-8-temporal-qa/duration_training_dataset.txt\"\n        \n        # Use multi-task data module\n        print(\"Setting up multi-task data module...\")\n        data_module = MultiTaskDataModule(config, date_train_path, duration_train_path)\n        \n        print(\"Setting up model...\")\n        model = TemporalTrainer(config)\n        \n        trainer = L.Trainer(\n            max_epochs=config.num_epochs,\n            accelerator='gpu' if torch.cuda.is_available() else 'cpu',\n            devices=1,\n            precision=16 if torch.cuda.is_available() else 32,\n            gradient_clip_val=1.0,\n            accumulate_grad_batches=2,\n            val_check_interval=0.25,\n            log_every_n_steps=25,\n            enable_checkpointing=True,\n            logger=True,\n            enable_progress_bar=True,\n            # NO max_steps - train đầy đủ!\n        )\n        \n        print(\"Starting full multi-task training...\")\n        trainer.fit(model, data_module)\n        \n        print(\"Running final test...\")\n        test_results = trainer.test(model, data_module)\n        \n        return model, trainer, config, test_results\n        \n    except Exception as e:\n        print(f\"Training error: {e}\")\n        traceback.print_exc()\n        return None, None, None, None","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-07T13:22:11.868238Z","iopub.execute_input":"2025-07-07T13:22:11.868453Z","iopub.status.idle":"2025-07-07T13:22:11.884350Z","shell.execute_reply.started":"2025-07-07T13:22:11.868438Z","shell.execute_reply":"2025-07-07T13:22:11.883862Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(\"Starting FULL temporal model training...\")\nmodel, trainer, config, test_results = train_temporal_model_full()\n\nif model is not None:\n    torch.save(model.state_dict(), \"temporal_model_full.pth\")\n    print(\"Full model saved!\")\n    print(f\"Test results: {test_results}\")\n    \n    print(\"\\n=== Example Inference ===\")\n    \n    date_question = \"Thời gian 1 năm và 2 tháng trước tháng 6, 1297 là khi nào?\"\n    date_answer = inference_date_arithmetic(model, date_question)\n    print(f\"Date Q: {date_question}\")\n    print(f\"Date A: {date_answer}\")\n    \n    try:\n        duration_context = \"Tôi đang sửa chữa chiếc xe đạp bị hỏng.\"\n        duration_question = \"Mất thời gian bao lâu để sửa chữa chiếc xe đạp?\"\n        duration_options = [\"30 phút\", \"1 tháng\", \"10 phút\", \"2 giờ\"]\n        duration_answers = inference_duration_qa(model, duration_context, duration_question, duration_options)\n        print(f\"\\nDuration Context: {duration_context}\")\n        print(f\"Duration Q: {duration_question}\")\n        print(f\"Duration Options: {duration_options}\")\n        print(f\"Duration A: {duration_answers}\")\n    except Exception as e:\n        print(f\"Duration inference error: {e}\")\n    \nelse:\n    print(\"Training failed!\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-07T13:22:11.884996Z","iopub.execute_input":"2025-07-07T13:22:11.885214Z","execution_failed":"2025-07-07T14:46:42.930Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}